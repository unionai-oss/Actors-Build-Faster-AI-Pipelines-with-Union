{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a3633b",
   "metadata": {},
   "source": [
    "# âš¡ Build Faster AI Pipelines with Union Actors Example\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/unionai-oss/Actors-Build-Faster-AI-Pipelines-with-Union/blob/main/faster_ai_pipelines_tutorial.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This notebook contains examples of getting started with Union Actors.\n",
    "\n",
    "Actors in Union let you reuse a container and its environment across multiple tasks, skipping the costly overhead of starting a fresh container every time.\n",
    "\n",
    "If you're unfamiliar with Union, it is a workflow and inference platform, often used witn complex data pipelines and training AI models.\n",
    "\n",
    "Read these for more information on Actors:\n",
    "- Supercharge your AI workflows with Actors\n",
    "- Union Actors documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a28429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the union sdk\n",
    "!pip install union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4eb9a",
   "metadata": {},
   "source": [
    "Sign up to [Union serverless](https://www.union.ai/) and run the code cell below. This will authenticate this environment to run on Union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!union create login --serverless --auth device-flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a7b10",
   "metadata": {},
   "source": [
    "## Simple Union Actors example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4183c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile hello_actors.py\n",
    "\n",
    "import union\n",
    "\n",
    "actor = union.ActorEnvironment(\n",
    "    name=\"my-actor-container\", # unique name for the actor env\n",
    "    replica_count=1,# Number of actor replicas to provision.\n",
    "    ttl_seconds=120,  # Keep the actor alive even when idle\n",
    "    requests=union.Resources(cpu=\"2\", mem=\"300Mi\"), # Compute resources actor requires\n",
    ")\n",
    "# update to just @task if you want to see the difference\n",
    "@actor.task\n",
    "def add_ints(num1: int, num2: int) -> int:\n",
    "    return num1 + num2\n",
    "\n",
    "@union.workflow\n",
    "def wf_add()  -> int:\n",
    "  num = add_ints(4, 2)\n",
    "  num = add_ints(num, 5)\n",
    "  num = add_ints(num, 2)\n",
    "  num = add_ints(num, 4)\n",
    "\n",
    "  return num\n",
    "\n",
    "# once authenticated, run the workflow with:\n",
    "# union run --remote hello_actors.py wf_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbc427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the workflows on Union\n",
    "!union run --remote hello_actors.py wf_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476e80e",
   "metadata": {},
   "source": [
    "## Going Deeper: Caching with @actor_cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5864b6",
   "metadata": {},
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb66821",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile actors_cache.py\n",
    "\n",
    "import union\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from flytekit import ImageSpec, Resources\n",
    "from union.actor import ActorEnvironment\n",
    "\n",
    "image = ImageSpec(\n",
    "    packages=[\n",
    "        \"union\",\n",
    "        \"transformers\",\n",
    "        \"torch\",\n",
    "        \"accelerate\",\n",
    "    ],\n",
    "    builder=\"union\",\n",
    ")\n",
    "\n",
    "llm_actor = ActorEnvironment(\n",
    "    name=\"gpu-llm-actor\",\n",
    "    container_image=image,\n",
    "    replica_count=1,\n",
    "    ttl_seconds=120,\n",
    "    requests=Resources(cpu=\"1\", mem=\"2000Mi\", gpu=\"1\"),\n",
    ")\n",
    "\n",
    "\n",
    "@union.actor_cache\n",
    "def load_model(model_name: str = \"microsoft/Phi-4-mini-instruct\") -> pipeline:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"cuda\",\n",
    "        torch_dtype=\"auto\",\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "@llm_actor.task\n",
    "def actor_model_predict(query: str, prev_summary: str =\"nothing yet.\") -> str:\n",
    "    nlp_pipeline = load_model()\n",
    "\n",
    "    # Chain query using the previous output\n",
    "    full_query = (\n",
    "        f\"{query} Previously you told me about {prev_summary}.\"\n",
    "        \"Keep answers short and 1 sentence long.\"\n",
    "        \"Include a list of all insects we discussed after the answer.\"\n",
    "    )\n",
    "\n",
    "    predictions = nlp_pipeline(full_query, batch_size=1, return_full_text=False)\n",
    "    return predictions[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "@union.workflow\n",
    "def wf_text_gen() -> str:\n",
    "    result_ant = actor_model_predict(query=\"What is an ant?\")\n",
    "    result_bee = actor_model_predict(query=\"What is a bee\", prev_summary=result_ant)\n",
    "    result_wasp = actor_model_predict(query=\"What is a wasp\", prev_summary=result_bee)\n",
    "    return result_wasp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b655b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!union run --remote actors_cache.py wf_text_gen"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
